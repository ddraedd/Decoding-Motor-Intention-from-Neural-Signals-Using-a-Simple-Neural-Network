{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddraedd/Decoding-Motor-Intention-from-Neural-Signals-Using-a-Simple-Neural-Network/blob/main/Kalman_Filter%2BSmoother_Implementation_for_Neural_Decoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR6tHZSNjFX3",
        "outputId": "701e469b-1ebf-4626-e9ca-e75d7d00cc80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import os"
      ],
      "metadata": {
        "id": "gqH7vaZM4UQC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAT_FILE_PATH = '/content/drive/MyDrive/primate spike data/data_and_scripts/source_data/processed/MT_S1_processed.mat'\n",
        "\n",
        "# Kalman Filter Parameters\n",
        "STATE_DIM = 5  # [pos_x, pos_y, vel_x, vel_y, 1]\n",
        "DELTA_T = 0.01 # 10 ms bins\n",
        "TRAIN_TEST_SPLIT_RATIO = 0.8 # 80% for training, 20% for testing\n",
        "\n",
        "# --- Data Loading and Preprocessing ---\n",
        "\n",
        "def load_and_preprocess_data(filepath, dt):\n",
        "    \"\"\"\n",
        "    Loads and preprocesses data from the specified .mat file using options\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the processed .mat file.\n",
        "        dt (float): Time step duration in seconds.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (states, measurements)\n",
        "               - states: List of numpy arrays, each [num_steps, state_dim] for a trial.\n",
        "               - measurements: List of numpy arrays, each [num_steps, num_neurons] for a trial.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"Loading data from: {filepath}\")\n",
        "    mat = scipy.io.loadmat(filepath, squeeze_me=True, struct_as_record=False)\n",
        "    data = mat['Data']\n",
        "    kinematics = data.kinematics  # Columns: 1:x_pos, 2:y_pos, 3:x_vel, 4:y_vel, 5:x_acc, 6:y_acc, 7:time\n",
        "    spikes_pmd = data.neural_data_PMd # dim = [neurons x time_bins]\n",
        "    num_reaches = kinematics.shape[0] # number of rows\n",
        "    print(f\"Found {num_reaches} reaches/trials.\")\n",
        "\n",
        "    states = []\n",
        "    measurements = []\n",
        "\n",
        "    for i in range(num_reaches):\n",
        "\n",
        "        # construct the state vector Xt\n",
        "        kin_reach = kinematics[i][:, [0, 1, 2, 3]] # Shape: [num_steps, 4]\n",
        "        num_steps = kin_reach.shape[0]    # steps = number of time bin\n",
        "        state_reach = np.hstack([kin_reach, np.ones((num_steps, 1))]) # Adding a column of 1's\n",
        "        # print(kin_reach, num_steps, state_reach)\n",
        "\n",
        "        # collect observations Yt\n",
        "        neural_reach = spikes_pmd[i].T # Shape: [num_steps, num_neurons]\n",
        "        neural_reach = np.sqrt(np.maximum(0, neural_reach)) # Apply square root transform\n",
        "\n",
        "        # Ensure consistent number of steps\n",
        "        min_steps = min(state_reach.shape[0], neural_reach.shape[0])\n",
        "        if min_steps < 2: # Need at least 2 steps for training estimates\n",
        "             print(f\"Skipping reach {i+1}: Insufficient time steps ({min_steps}).\")\n",
        "             continue\n",
        "\n",
        "        states.append(state_reach[:min_steps, :])\n",
        "        measurements.append(neural_reach[:min_steps, :])\n",
        "\n",
        "    if not states:\n",
        "        print(\"Error: No valid reaches processed. Check data or preprocessing steps.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Successfully processed {len(states)} reaches.\")\n",
        "    num_neurons = measurements[0].shape[1]\n",
        "    print(f\"Number of neurons: {num_neurons}\")\n",
        "\n",
        "    return states, measurements\n",
        "\n",
        "# load_and_preprocess_data(MAT_FILE_PATH, DELTA_T)"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "Q_kQH7fmi-F9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Parameter Estimation ---\n",
        "\n",
        "def estimate_kalman_params(states_train, measurements_train, dt):\n",
        "    \"\"\"\n",
        "    Estimates Kalman filter parameters A, C, Q, R from training data.\n",
        "\n",
        "    Args:\n",
        "        states_train (list): List of state arrays for training trials.\n",
        "        measurements_train (list): List of measurement arrays for training trials.\n",
        "        dt (float): Time step duration.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (A, C, Q, R) estimated matrices.\n",
        "    \"\"\"\n",
        "    print(\"Estimating Kalman filter parameters...\")\n",
        "    state_dim = states_train[0].shape[1]\n",
        "    measurement_dim = measurements_train[0].shape[1]\n",
        "\n",
        "    # --- Estimate A and Q ---\n",
        "    # Option 1: Fixed A based on physics (constant velocity model)\n",
        "    # A = np.array([\n",
        "    #     [1, 0, dt, 0, 0],\n",
        "    #     [0, 1, 0, dt, 0],\n",
        "    #     [0, 0, 1, 0, 0],\n",
        "    #     [0, 0, 0, 1, 0],\n",
        "    #     [0, 0, 0, 0, 1]\n",
        "    # ])\n",
        "    # print(\"Using fixed constant velocity model for A.\")\n",
        "\n",
        "    # Collect state transitions to estimate Q\n",
        "    all_states_t = []\n",
        "    all_states_t_plus_1 = []\n",
        "    for state_trial in states_train:\n",
        "        all_states_t.append(state_trial[:-1, :]) # x_t\n",
        "        all_states_t_plus_1.append(state_trial[1:, :]) # x_{t+1}\n",
        "\n",
        "    X_t = np.vstack(all_states_t)\n",
        "    X_t_plus_1 = np.vstack(all_states_t_plus_1)\n",
        "\n",
        "    # Option 2: Estimate A using linear regression (Uncomment to use)\n",
        "    print(\"Estimating A using linear regression...\")\n",
        "    reg_A = LinearRegression(fit_intercept=False)\n",
        "    reg_A.fit(X_t, X_t_plus_1)\n",
        "    A = reg_A.coef_\n",
        "    print(\"A estimated via regression.\")\n",
        "\n",
        "    # Calculate process noise residuals w_t = x_{t+1} - A @ x_t\n",
        "    W = X_t_plus_1 - X_t @ A.T # Note the transpose for matrix multiplication alignment\n",
        "    Q = np.cov(W.T) # Covariance of residuals\n",
        "    print(\"Q estimated.\")\n",
        "\n",
        "    # --- Estimate C and R ---\n",
        "    # Collect all states (x_t) and corresponding measurements (y_t)\n",
        "    all_states_for_C = []\n",
        "    all_measurements_for_C = []\n",
        "    for i in range(len(states_train)):\n",
        "        # Use all time steps from each trial\n",
        "        all_states_for_C.append(states_train[i])\n",
        "        all_measurements_for_C.append(measurements_train[i])\n",
        "\n",
        "    X_for_C = np.vstack(all_states_for_C)\n",
        "    Y_for_C = np.vstack(all_measurements_for_C)\n",
        "\n",
        "    # Estimate C using linear regression: y_t = C @ x_t\n",
        "    print(\"Estimating C using linear regression...\")\n",
        "    reg_C = LinearRegression(fit_intercept=False) # Intercept is handled by the '1' in state vector\n",
        "    reg_C.fit(X_for_C, Y_for_C)\n",
        "    C = reg_C.coef_ # Shape: [measurement_dim, state_dim]\n",
        "    print(\"C estimated.\")\n",
        "\n",
        "    # Calculate measurement noise residuals v_t = y_t - C @ x_t\n",
        "    V = Y_for_C - X_for_C @ C.T # Note the transpose\n",
        "    # Estimate R as covariance of residuals\n",
        "    # Option 1: Full covariance matrix (can be large and prone to overfitting)\n",
        "    # R = np.cov(V.T)\n",
        "    # Option 2: Diagonal R (assumes independent noise across neurons - more robust)\n",
        "    R = np.diag(np.var(V, axis=0))\n",
        "    print(\"R estimated (diagonal).\")\n",
        "\n",
        "    # Regularization\n",
        "    # Add small identity matrix to Q and R to ensure invertibility and stability\n",
        "    Q += np.eye(state_dim) * 1e-7\n",
        "    R += np.eye(measurement_dim) * 1e-7\n",
        "    # Ensure Q and R are symmetric\n",
        "    Q = (Q + Q.T) / 2\n",
        "    R = (R + R.T) / 2\n",
        "\n",
        "\n",
        "    print(\"Parameter estimation complete.\")\n",
        "    return A, C, Q, R\n",
        "\n",
        "# --- Kalman Filter Implementation (Forward Pass) ---\n",
        "\n",
        "def kalman_filter(measurements_trial, A, C, Q, R, initial_state, initial_cov):\n",
        "    \"\"\"\n",
        "    Applies the Kalman filter (forward pass) to a single trial of measurements.\n",
        "    Matches the version in the reference notebook (returns only filtered results).\n",
        "\n",
        "    Args:\n",
        "        measurements_trial (np.array): Measurement vector sequence for the trial [num_steps, num_neurons].\n",
        "        A (np.array): State transition matrix.\n",
        "        C (np.array): Measurement matrix.\n",
        "        Q (np.array): Process noise covariance.\n",
        "        R (np.array): Measurement noise covariance.\n",
        "        initial_state (np.array): Initial state estimate (x_0|0).\n",
        "        initial_cov (np.array): Initial error covariance (P_0|0).\n",
        "\n",
        "    Returns:\n",
        "        tuple: (x_filt, P_filt)\n",
        "               - x_filt: Filtered state estimates [num_steps, state_dim].\n",
        "               - P_filt: Filtered error covariance estimates [num_steps, state_dim, state_dim].\n",
        "    \"\"\"\n",
        "    num_steps = measurements_trial.shape[0]\n",
        "    state_dim = A.shape[0]\n",
        "\n",
        "    # Store estimates from the forward pass\n",
        "    x_filt_arr = np.zeros((num_steps, state_dim))        # x_{k|k}\n",
        "    P_filt_arr = np.zeros((num_steps, state_dim, state_dim)) # P_{k|k}\n",
        "\n",
        "    # Initialization\n",
        "    x_filt_k_minus_1 = initial_state # x_{0|0}\n",
        "    P_filt_k_minus_1 = initial_cov   # P_{0|0}\n",
        "\n",
        "    for k in range(num_steps):\n",
        "        # --- Prediction (Time Update) ---\n",
        "        # x_{k|k-1} = A @ x_{k-1|k-1}\n",
        "        x_pred_k = A @ x_filt_k_minus_1\n",
        "        # P_{k|k-1} = A @ P_{k-1|k-1} @ A.T + Q\n",
        "        P_pred_k = A @ P_filt_k_minus_1 @ A.T + Q\n",
        "        # Ensure P_pred_k is symmetric\n",
        "        P_pred_k = (P_pred_k + P_pred_k.T) / 2\n",
        "\n",
        "        # --- Update (Measurement Update) ---\n",
        "        y_k = measurements_trial[k, :] # Current measurement y_k\n",
        "\n",
        "        # Innovation or measurement residual: y_k - C @ x_{k|k-1}\n",
        "        innovation = y_k - C @ x_pred_k\n",
        "\n",
        "        # Innovation covariance: S_k = C @ P_{k|k-1} @ C.T + R\n",
        "        S_k = C @ P_pred_k @ C.T + R\n",
        "        # Ensure S_k is symmetric\n",
        "        S_k = (S_k + S_k.T) / 2\n",
        "\n",
        "        # Optimal Kalman gain: K_k = P_{k|k-1} @ C.T @ inv(S_k)\n",
        "        try:\n",
        "            # Use pseudo-inverse for numerical stability if S_k is ill-conditioned\n",
        "            S_k_inv = np.linalg.pinv(S_k)\n",
        "            # S_k_inv = np.linalg.inv(S_k) # Standard inverse\n",
        "            K_k = P_pred_k @ C.T @ S_k_inv\n",
        "        except np.linalg.LinAlgError:\n",
        "            print(f\"Warning: S_k matrix inversion failed at step {k}. Using pseudo-inverse.\")\n",
        "            K_k = P_pred_k @ C.T @ np.linalg.pinv(S_k)\n",
        "\n",
        "\n",
        "        # Updated state estimate: x_{k|k} = x_{k|k-1} + K_k @ innovation\n",
        "        x_filt_k = x_pred_k + K_k @ innovation\n",
        "\n",
        "        # Updated error covariance: P_{k|k} = (I - K_k @ C) @ P_{k|k-1}\n",
        "        I = np.eye(state_dim)\n",
        "        P_filt_k = (I - K_k @ C) @ P_pred_k\n",
        "        # Ensure P_filt_k is symmetric\n",
        "        P_filt_k = (P_filt_k + P_filt_k.T) / 2\n",
        "\n",
        "        # Store filtered results for this step\n",
        "        x_filt_arr[k, :] = x_filt_k\n",
        "        P_filt_arr[k, :, :] = P_filt_k\n",
        "\n",
        "        # Update for next iteration\n",
        "        x_filt_k_minus_1 = x_filt_k\n",
        "        P_filt_k_minus_1 = P_filt_k\n",
        "\n",
        "    return x_filt_arr, P_filt_arr\n",
        "\n",
        "# --- Evaluation ---\n",
        "\n",
        "def evaluate_predictions(true_states_list, predicted_states_list):\n",
        "    \"\"\"\n",
        "    Evaluates the prediction performance using MSE and R2 score.\n",
        "    Matches the version in the reference notebook.\n",
        "\n",
        "    Args:\n",
        "        true_states_list (list): List of true state arrays for test trials.\n",
        "        predicted_states_list (list): List of predicted state arrays for test trials.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing evaluation metrics (MSE_x, MSE_y, R2_x, R2_y).\n",
        "    \"\"\"\n",
        "    all_true_pos = np.vstack([s[:, :2] for s in true_states_list]) # Extract true x, y positions\n",
        "    all_pred_pos = np.vstack([p[:, :2] for p in predicted_states_list]) # Extract predicted x, y positions\n",
        "\n",
        "    mse_x = mean_squared_error(all_true_pos[:, 0], all_pred_pos[:, 0])\n",
        "    mse_y = mean_squared_error(all_true_pos[:, 1], all_pred_pos[:, 1])\n",
        "    r2_x = r2_score(all_true_pos[:, 0], all_pred_pos[:, 0])\n",
        "    r2_y = r2_score(all_true_pos[:, 1], all_pred_pos[:, 1])\n",
        "\n",
        "    print(\"\\n--- Evaluation Results (Filtered) ---\")\n",
        "    print(f\"Position X - MSE: {mse_x:.4f}, R2: {r2_x:.4f}\")\n",
        "    print(f\"Position Y - MSE: {mse_y:.4f}, R2: {r2_y:.4f}\")\n",
        "\n",
        "    return {'MSE_x': mse_x, 'MSE_y': mse_y, 'R2_x': r2_x, 'R2_y': r2_y}\n",
        "\n",
        "# --- Plotting ---\n",
        "\n",
        "def plot_trajectory(true_states_trial, predicted_states_trial, trial_index):\n",
        "    \"\"\"\n",
        "    Plots the true vs predicted trajectory for a single trial.\n",
        "    Matches the version in the reference notebook.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.plot(true_states_trial[:, 0], true_states_trial[:, 1], 'b-', linewidth=2, label='True Trajectory')\n",
        "    plt.plot(predicted_states_trial[:, 0], predicted_states_trial[:, 1], 'r--', linewidth=1.5, label='Predicted Trajectory')\n",
        "    plt.scatter(true_states_trial[0, 0], true_states_trial[0, 1], c='blue', marker='o', s=100, label='Start (True)', zorder=5)\n",
        "    plt.scatter(predicted_states_trial[0, 0], predicted_states_trial[0, 1], c='red', marker='x', s=100, label='Start (Pred)', zorder=5)\n",
        "    plt.xlabel(\"X Position (cm)\")\n",
        "    plt.ylabel(\"Y Position (cm)\")\n",
        "    plt.title(f\"Kalman Filter Prediction - Trial {trial_index + 1}\")\n",
        "    plt.legend()\n",
        "    plt.axis('equal')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# --- Main Execution ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Load and Preprocess Data\n",
        "    states, measurements = load_and_preprocess_data(MAT_FILE_PATH, DELTA_T, USE_DUMMY_DATA)\n",
        "\n",
        "    if states is not None and measurements is not None:\n",
        "        # 2. Split into Training and Testing Sets\n",
        "        indices = list(range(len(states)))\n",
        "        train_indices, test_indices = train_test_split(indices, train_size=TRAIN_TEST_SPLIT_RATIO, random_state=42)\n",
        "\n",
        "        states_train = [states[i] for i in train_indices]\n",
        "        measurements_train = [measurements[i] for i in train_indices]\n",
        "        states_test = [states[i] for i in test_indices]\n",
        "        measurements_test = [measurements[i] for i in test_indices]\n",
        "\n",
        "        print(f\"\\nData split: {len(states_train)} training trials, {len(states_test)} testing trials.\")\n",
        "\n",
        "        # 3. Estimate Kalman Parameters from Training Data\n",
        "        A, C, Q, R = estimate_kalman_params(states_train, measurements_train, DELTA_T)\n",
        "\n",
        "        # 4. Run Kalman Filter on Test Data\n",
        "        # Determine initial state and covariance from training data\n",
        "        initial_states_train = np.array([s[0, :] for s in states_train]) # State at t=0 for all train trials\n",
        "        initial_state_mean = np.mean(initial_states_train, axis=0)\n",
        "        initial_state_cov = np.cov(initial_states_train.T) + np.eye(STATE_DIM) * 1e-6 # Add small value for stability\n",
        "\n",
        "        print(\"\\nRunning Kalman filter on test trials...\")\n",
        "        predicted_states_list = [] # This will store the filtered states\n",
        "\n",
        "        for i, test_trial_measurements in enumerate(measurements_test):\n",
        "            print(f\"Filtering trial {i+1}/{len(states_test)}...\")\n",
        "            # --- Forward Pass (Kalman Filter) ---\n",
        "            x_filt, P_filt = kalman_filter(\n",
        "                test_trial_measurements, A, C, Q, R, initial_state_mean, initial_state_cov\n",
        "            )\n",
        "            predicted_states_list.append(x_filt) # Store filtered states\n",
        "\n",
        "        print(\"Filtering complete.\")\n",
        "\n",
        "        # 5. Evaluate Predictions (using filtered results)\n",
        "        evaluation_metrics = evaluate_predictions(states_test, predicted_states_list)\n",
        "\n",
        "        # 6. Plot results for a few test trials (using filtered results)\n",
        "        num_trials_to_plot = min(3, len(states_test))\n",
        "        print(f\"\\nPlotting filtered trajectories for the first {num_trials_to_plot} test trials...\")\n",
        "        for i in range(num_trials_to_plot):\n",
        "            plot_trajectory(states_test[i], predicted_states_list[i], test_indices[i]) # Pass original index for title\n",
        "\n",
        "    else:\n",
        "        print(\"\\nExiting due to data loading/processing errors.\")"
      ],
      "metadata": {
        "id": "l2040yIx7aX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}